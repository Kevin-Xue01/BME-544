{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BME 544 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from scipy.signal import hilbert\n",
    "import re\n",
    "\n",
    "np.random.seed(42)\n",
    "show_gt = False\n",
    "\n",
    "# Directory containing the .wav files\n",
    "wav_directory = \"DC1_Recordings/\"\n",
    "\n",
    "# List of time slices (start, stop) in seconds\n",
    "time_slices = [\n",
    "    [20, 35], [36, 55], [1, 16], [11, 20], [0, 33], [10, 15], [9, 31], [9, 26],\n",
    "    [9, 26], [3, 16], [7, 19], [3, 15], [18, 50], [8, 25], [13, 18], [6, 15],\n",
    "    [10, 23], [1, 29], [13, 32], [0, 12], [3, 17], [14, 27], [0, 8], [14, 28],\n",
    "    [0, 9], [9, 30], [0, 9], [0, 13], [11, 22], [2, 22]\n",
    "]\n",
    "\n",
    "# Normalize the audio signal\n",
    "def normalize_audio(audio):\n",
    "    \"\"\"Normalize audio signal to the range [-1, 1].\"\"\"\n",
    "    return audio / np.max(np.abs(audio))\n",
    "\n",
    "# Apply Rolling Median Filter (Window-based)\n",
    "def rolling_median_filter(audio, window_size):\n",
    "    \"\"\"Apply a median filter with a sliding window to the audio signal.\"\"\"\n",
    "    return signal.medfilt(audio, kernel_size=window_size)\n",
    "\n",
    "# Function to calculate signal envelope\n",
    "def calculate_envelope(signal):\n",
    "    \"\"\"Calculate the envelope of a signal using Hilbert transform.\"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    return np.abs(analytic_signal)\n",
    "\n",
    "def percussive_enhance(audio):\n",
    "    return librosa.effects.percussive(audio)\n",
    "\n",
    "def normalize_array(arr):\n",
    "    \"\"\"\n",
    "    Normalize an array to the range [0, 1].\n",
    "    \n",
    "    Parameters:\n",
    "    - arr (array-like): The array to normalize.\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_arr (ndarray): The normalized array.\n",
    "    \"\"\"\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr) + 1e-6)\n",
    "\n",
    "def weigh_peaks(peaks, heights, horizontal_gap_weight=1.75, vertical_gap_weight=0.5, horizontal_center_dist_weight=1.0, vertical_center_dist_weight=0.5):\n",
    "    peaks = np.asarray(peaks)\n",
    "    heights = np.asarray(heights)\n",
    "    \n",
    "    if len(peaks) < 2:\n",
    "        return np.ones_like(peaks, dtype=float)  # Default weight if no neighbors exist\n",
    "    \n",
    "    # Compute median offsets for distances to neighbors\n",
    "    median_horizontal_gap = np.median(np.diff(peaks)) if len(peaks) > 1 else 0\n",
    "    median_vertical_gap = np.median(np.abs(np.diff(heights))) if len(heights) > 1 else 0\n",
    "    \n",
    "    # Compute horizontal and vertical distances to neighbors\n",
    "    horizontal_gaps = np.zeros_like(peaks, dtype=float)\n",
    "    vertical_gaps = np.zeros_like(peaks, dtype=float)\n",
    "    \n",
    "    for i in range(len(peaks)):\n",
    "        if i == 0:\n",
    "            horizontal_gaps[i] = abs(peaks[i + 1] - peaks[i] - median_horizontal_gap)\n",
    "            vertical_gaps[i] = abs(heights[i + 1] - heights[i] - median_vertical_gap)\n",
    "        elif i == len(peaks) - 1:\n",
    "            horizontal_gaps[i] = abs(peaks[i] - peaks[i - 1] - median_horizontal_gap)\n",
    "            vertical_gaps[i] = abs(heights[i] - heights[i - 1] - median_vertical_gap)\n",
    "        else:\n",
    "            horizontal_gaps[i] = abs((peaks[i + 1] - peaks[i - 1]) / 2 - median_horizontal_gap)\n",
    "            vertical_gaps[i] = abs((abs(heights[i + 1] - heights[i]) + abs(heights[i] - heights[i - 1])) / 2 - median_vertical_gap)\n",
    "    \n",
    "    # Normalize horizontal and vertical distances before applying the weights\n",
    "    horizontal_gaps = normalize_array(horizontal_gaps)\n",
    "    vertical_gaps = normalize_array(vertical_gaps)\n",
    "    \n",
    "    # Calculate the distance of each peak_x (in peaks) and peak_y (in heights) to their respective medians\n",
    "    median_peak_x = np.median(peaks)\n",
    "    median_peak_y = np.median(heights)\n",
    "    \n",
    "    horizontal_center_dists = normalize_array(np.abs(peaks - median_peak_x))\n",
    "    vertical_center_dists = normalize_array(np.abs(heights - median_peak_y))\n",
    "    \n",
    "    # Compute weighted score including the new median-based weights\n",
    "    weights = (horizontal_gap_weight / (horizontal_gaps + 1e-2) + \n",
    "               vertical_gap_weight / (vertical_gaps + 1e-2) + \n",
    "               horizontal_center_dist_weight / (horizontal_center_dists + 1e-2) + \n",
    "               vertical_center_dist_weight / (vertical_center_dists + 1e-2))\n",
    "\n",
    "    # Normalize the final weights\n",
    "    weights = normalize_array(weights)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def extract_info(filename):\n",
    "    pattern = r\"(\\w+)_(\\d+)_(\\d+)\\.wav\"\n",
    "    match = re.match(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        key, start_pressure, end_pressure = match.groups()\n",
    "        return {\n",
    "            \"key\": key,\n",
    "            \"start_pressure\": int(start_pressure),\n",
    "            \"end_pressure\": int(end_pressure)\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "downsample_factor = 3\n",
    "median_filter_window_size = 15\n",
    "percentile_lower = 97\n",
    "percentile_upper = 99\n",
    "max_bpm = 120\n",
    "peak_prominence = 0.01\n",
    "convolution_window_length_seconds = 8\n",
    "crossing_threshold = 0.3\n",
    "\n",
    "output = []\n",
    "# Iterate through .wav files in the directory\n",
    "for i, filename in enumerate(sorted(os.listdir(wav_directory))):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        try:\n",
    "            info = extract_info(filename)\n",
    "            file_path = os.path.join(wav_directory, filename)\n",
    "            y, sr = librosa.load(file_path, sr=None)  # Load audio file with its original sampling rate\n",
    "\n",
    "            # Get the time slice for this file from the list\n",
    "            start_time, end_time = time_slices[i]\n",
    "\n",
    "            # Convert start and end times to sample indices\n",
    "            start_sample = int(start_time * sr)\n",
    "            end_sample = int(end_time * sr)\n",
    "            y_percussive = normalize_audio(percussive_enhance(y))\n",
    "\n",
    "            y_envelope = calculate_envelope(y_percussive)\n",
    "            y_downsampled = normalize_array(y_envelope[::downsample_factor])\n",
    "            y_median = rolling_median_filter(y_downsampled, median_filter_window_size)\n",
    "\n",
    "            percentile_lower_thresh = np.percentile(y_median, percentile_lower)\n",
    "            percentile_upper_thresh = np.percentile(y_median, percentile_upper)\n",
    "            masked_signal = np.where((y_median >= percentile_lower_thresh), y_median, 0)\n",
    "\n",
    "            # Find peaks in the masked signal\n",
    "            y_peaks, _ = signal.find_peaks(masked_signal, distance=int((sr * 60 / max_bpm) / downsample_factor), height=peak_prominence)\n",
    "            y_peaks = y_peaks[1:-1] # Ignore the first and last peaks\n",
    "            weights = weigh_peaks(y_peaks, y_median[y_peaks])\n",
    "\n",
    "            window_length_samples = int(convolution_window_length_seconds * sr / downsample_factor)\n",
    "            square_window = np.ones(window_length_samples)\n",
    "            weights_with_zeros = np.zeros_like(y_median)\n",
    "\n",
    "            weights_with_zeros[y_peaks] = weights\n",
    "\n",
    "            convolved_weights = normalize_array(signal.convolve(weights_with_zeros, square_window, mode='same'))\n",
    "\n",
    "            # Find the index of the max value in the convolved signal\n",
    "            max_idx = np.argmax(convolved_weights)\n",
    "\n",
    "            # Compute the derivative (finite differences)\n",
    "            derivative = np.diff(convolved_weights, prepend=0)\n",
    "\n",
    "            # Find the leftmost crossing point before max_idx with a positive derivative\n",
    "            left_crossing_idx = None\n",
    "            for i in range(max_idx):\n",
    "                if convolved_weights[i] >= crossing_threshold and derivative[i] > 0:\n",
    "                    left_crossing_idx = i\n",
    "                    break  # Stop at the first (leftmost) crossing\n",
    "\n",
    "            # Find the rightmost crossing point after max_idx with a negative derivative\n",
    "            right_crossing_idx = None\n",
    "            for i in range(len(convolved_weights) - 1, max_idx, -1):\n",
    "                if convolved_weights[i] >= crossing_threshold and derivative[i] < 0:\n",
    "                    right_crossing_idx = i\n",
    "                    break  # Stop at the first (rightmost) crossing\n",
    "            \n",
    "            systolic_pressure_est = info[\"start_pressure\"] + (left_crossing_idx / (len(y) - 1)) * (info[\"end_pressure\"] - info[\"start_pressure\"])\n",
    "            diastolic_pressure_est = info[\"start_pressure\"] + (right_crossing_idx / (len(y) - 1)) * (info[\"end_pressure\"] - info[\"start_pressure\"])\n",
    "\n",
    "            output.append({\n",
    "                \"filename\": filename,\n",
    "                \"systolic_pressure_est\": systolic_pressure_est,\n",
    "                \"diastolic_pressure_est\": diastolic_pressure_est\n",
    "            })\n",
    "            \n",
    "            plt.figure(figsize=(32, 14))\n",
    "\n",
    "            # 1. Original Signal\n",
    "            plt.subplot(3, 3, 1)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample, color='r', linestyle='--', label='Start')\n",
    "                plt.axvline(x=end_sample, color='g', linestyle='--', label='End')\n",
    "            plt.plot(normalize_audio(y))\n",
    "            plt.title(\"Original Signal\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 2. Percussive Enhanced (Normalized)\n",
    "            plt.subplot(3, 3, 2)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample, color='g', linestyle='--')\n",
    "            plt.plot(y_percussive)\n",
    "            plt.title(\"Percussive Enhanced\")\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 3. Envelope Downsampled\n",
    "            plt.subplot(3, 3, 3)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(y_downsampled)\n",
    "            plt.title(\"Enveloped + Rectified, Downsampled\")\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 4. Median Filtered\n",
    "            plt.subplot(3, 3, 4)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(y_median)\n",
    "            plt.title(\"Median Filtered\")\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 5. Masked Signal\n",
    "            plt.subplot(3, 3, 5)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(masked_signal)\n",
    "            plt.title(\"Percentile Masked\")\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 6. Median Filtered with Peaks\n",
    "            plt.subplot(3, 3, 6)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(y_median, label=\"Filtered Signal\")\n",
    "            plt.plot(y_peaks, y_median[y_peaks], \"rx\", label=\"Detected Peaks\")\n",
    "            plt.title(\"Median Filtered with Peaks\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 7. Median Filtered with Weighted Peaks\n",
    "            plt.subplot(3, 3, 7)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(y_median, label=\"Filtered Signal\")\n",
    "            plt.plot(y_peaks, weights, \"rx\", label=\"Weighted Peaks\")\n",
    "            plt.title(\"Median Filtered with Weighted Peaks\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 8. Convolved\n",
    "            plt.subplot(3, 3, 8)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.plot(convolved_weights, \"g--\", label=\"Convolved Weights\")\n",
    "            plt.title(\"Convolved Weighted Peaks\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # 9. Normalized Convolved with Left & Right Points Found\n",
    "            plt.subplot(3, 3, 9)\n",
    "            if show_gt:\n",
    "                plt.axvline(x=start_sample // downsample_factor, color='r', linestyle='--')\n",
    "                plt.axvline(x=end_sample // downsample_factor, color='g', linestyle='--')\n",
    "            plt.axhline(y=crossing_threshold, color='b', linestyle='--', label='Threshold')\n",
    "            plt.plot(convolved_weights, \"g--\")\n",
    "            if left_crossing_idx is not None:\n",
    "                plt.axvline(left_crossing_idx, color='purple', linestyle='-.', label=\"Estimated Systolic Pressure\")\n",
    "            if right_crossing_idx is not None:\n",
    "                plt.axvline(right_crossing_idx, color='orange', linestyle='-.', label=\"Estimated Diastolic Pressure\")\n",
    "            plt.title(\"Convolved Weighted Peaks with Systolic & Diastolic Sample Index\")\n",
    "            plt.legend()\n",
    "            plt.xlabel(\"Samples\")\n",
    "            plt.ylabel(\"Amplitude\")\n",
    "\n",
    "            # Layout & Title\n",
    "            plt.tight_layout()\n",
    "            if show_gt:\n",
    "                plt.suptitle(f'File {filename} | Interval: {start_time}s - {end_time}s', fontsize=16, y=1.05)\n",
    "            else:\n",
    "                plt.suptitle(f'File {filename}', fontsize=16, y=1.05)\n",
    "            plt.show()\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"Skipping {filename}: Unable to parse pressure values\")\n",
    "\n",
    "df = pd.DataFrame(output)\n",
    "df.to_csv(\"Assignment_2_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bme544",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
